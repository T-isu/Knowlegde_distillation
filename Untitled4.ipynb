{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb8f55-664c-41ca-9c1e-e5a4eb6cef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models.detection as detection\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "from torchvision.ops import box_iou\n",
    "\n",
    "from collate_fn import custom_collate, CustomCocoDataset\n",
    "\n",
    "# Transformation and dataset loading\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((640, 640)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.229, 0.224))\n",
    "    ])\n",
    "\n",
    "# Loading models\n",
    "def load_models(device):\n",
    "    teacher_model = detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    teacher_model.to(device).eval()\n",
    "\n",
    "    student_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "    student_model.to(device).train()\n",
    "\n",
    "    return teacher_model, student_model\n",
    "\n",
    "# Distillation loss function\n",
    "def distillation_loss(student_output, teacher_output, alpha=0.5, temperature=2):\n",
    "    student_probs = torch.sigmoid(student_output/temperature)\n",
    "    teacher_probs = torch.sigmoid(teacher_output/temperature)\n",
    "    loss = torch.nn.functional.mse_loss(student_probs, teacher_probs)\n",
    "    return alpha * loss\n",
    "\n",
    "# Training loop\n",
    "def train_one_epoch(student_model, teacher_model, dataloader, optimizer, device, temperature=2):\n",
    "    student_model.train()\n",
    "    for images, targets in dataloader:\n",
    "        images = [img.to(device) for img in images]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_output = teacher_model(images)\n",
    "\n",
    "        student_output = student_model(images)\n",
    "        loss = distillation_loss(student_output, teacher_output)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, _ in data_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            outputs = model(images)\n",
    "            # Dummy accuracy calculation; replace with appropriate logic\n",
    "            correct += (outputs == outputs).sum().item()  # Dummy, replace with actual logic\n",
    "            total += len(outputs)\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "def main():\n",
    "    device = torch.device('mps')\n",
    "    dataset_root = '/Users/suvannanda/Desktop/objd/cocodata/train2017'\n",
    "    annotation_file = '/Users/suvannanda/Desktop/objd/cocodata/annotations/instances_train2017.json'\n",
    "\n",
    "    coco_dataset = CustomCocoDataset(dataset_root, annotation_file, transform=get_transform())\n",
    "    data_loader = DataLoader(coco_dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=custom_collate)\n",
    "\n",
    "    teacher_model, student_model = load_models(device)\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    train_one_epoch(student_model, teacher_model, data_loader, optimizer, device)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = evaluate_model(student_model, data_loader, device)\n",
    "    print(f\"Model Accuracy: {accuracy}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15e1a8f-d77f-4f97-9922-79b7c0951b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=58.37s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/suvannanda/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-2-27 Python-3.8.16 torch-2.2.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13GFamilyCommandBuffer: 0x47883e890>\n",
      "    label = <none> \n",
      "    device = <AGXG13GDevice: 0x3b1f7b200>\n",
      "        name = Apple M1 \n",
      "    commandQueue = <AGXG13GFamilyCommandQueue: 0x3b1f79400>\n",
      "        label = <none> \n",
      "        device = <AGXG13GDevice: 0x3b1f7b200>\n",
      "            name = Apple M1 \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m     train_one_epoch(student_model, teacher_model, data_loader, optimizer, device)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 68\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 65\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(student_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Train the model for one epoch (expand as needed)\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(student_model, teacher_model, dataloader, optimizer, device, temperature)\u001b[0m\n\u001b[1;32m     37\u001b[0m images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([img\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images])  \u001b[38;5;66;03m# Stack and move to device\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 40\u001b[0m     teacher_output \u001b[38;5;241m=\u001b[39m \u001b[43mteacher_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Obtain logits from Faster R-CNN\u001b[39;00m\n\u001b[1;32m     42\u001b[0m student_output \u001b[38;5;241m=\u001b[39m student_model(images)  \u001b[38;5;66;03m# Output from YOLO\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Assuming both outputs are compatible for distillation; you may need to adjust this depending on the actual output structure\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'logits'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models.detection as detection\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "\n",
    "from collate_fn import custom_collate, CustomCocoDataset\n",
    "\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((640, 640)),  # Resize to match YOLOv5 input\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.229, 0.224))  # Normalization for ImageNet pre-trained models\n",
    "    ])\n",
    "\n",
    "def load_models(device):\n",
    "    # Faster R-CNN with a ResNet-50 backbone as the teacher\n",
    "    teacher_model = detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    teacher_model.to(device).eval()\n",
    "\n",
    "    # YOLOv5 small as the student\n",
    "    student_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "    student_model.to(device).train()\n",
    "\n",
    "    return teacher_model, student_model\n",
    "\n",
    "def distillation_loss(student_output, teacher_output, alpha=0.5, temperature=2):\n",
    "    # Assuming outputs are the raw class logits\n",
    "    student_probs = torch.sigmoid(student_output / temperature)\n",
    "    teacher_probs = torch.sigmoid(teacher_output / temperature)\n",
    "    loss = torch.nn.functional.mse_loss(student_probs, teacher_probs)\n",
    "    return alpha * loss\n",
    "\n",
    "def train_one_epoch(student_model, teacher_model, dataloader, optimizer, device, temperature=2):\n",
    "    student_model.train()\n",
    "    for images, _ in dataloader:\n",
    "        images = torch.stack([img.to(device) for img in images])  # Stack and move to device\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_output = teacher_model(images)[0]['logits']  # Obtain logits from Faster R-CNN\n",
    "\n",
    "        student_output = student_model(images)  # Output from YOLO\n",
    "\n",
    "        # Assuming both outputs are compatible for distillation; you may need to adjust this depending on the actual output structure\n",
    "        loss = distillation_loss(student_output, teacher_output)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def main():\n",
    "    device = torch.device('mps')\n",
    "    dataset_root = '/Users/suvannanda/Desktop/objd/cocodata/train2017'\n",
    "    annotation_file = '/Users/suvannanda/Desktop/objd/cocodata/annotations/instances_train2017.json'\n",
    "\n",
    "    # Initialize dataset and dataloader\n",
    "    coco_dataset = CustomCocoDataset(dataset_root, annotation_file, transform=get_transform())\n",
    "    data_loader = DataLoader(coco_dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=custom_collate)\n",
    "\n",
    "    # Load models and optimizer\n",
    "    teacher_model, student_model = load_models(device)\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model for one epoch (expand as needed)\n",
    "    train_one_epoch(student_model, teacher_model, data_loader, optimizer, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7986a3ef-a813-4980-9238-50b0a76d51bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=58.27s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/suvannanda/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-2-27 Python-3.8.16 torch-2.2.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13GFamilyCommandBuffer: 0x4cf62a530>\n",
      "    label = <none> \n",
      "    device = <AGXG13GDevice: 0x3b1f7b200>\n",
      "        name = Apple M1 \n",
      "    commandQueue = <AGXG13GFamilyCommandQueue: 0x3b1f79400>\n",
      "        label = <none> \n",
      "        device = <AGXG13GDevice: 0x3b1f7b200>\n",
      "            name = Apple M1 \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 80 but got size 40 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m     train_one_epoch(student_model, teacher_model, data_loader, optimizer, device)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 72\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(student_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Train the model for one epoch\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 41\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(student_model, teacher_model, dataloader, optimizer, device, temperature)\u001b[0m\n\u001b[1;32m     39\u001b[0m     student_scores \u001b[38;5;241m=\u001b[39m student_outputs[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m4\u001b[39m]  \u001b[38;5;66;03m# Assuming the 5th column in output are the confidences\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(student_outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m---> 41\u001b[0m     student_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstudent_outputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust indexing if necessary\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Calculate the distillation loss using MSE on the scores\u001b[39;00m\n\u001b[1;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m distillation_loss(student_scores, teacher_scores, temperature)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 80 but got size 40 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models.detection as detection\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "\n",
    "from collate_fn import custom_collate, CustomCocoDataset\n",
    "\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((640, 640)),  # Resize to match YOLOv5 input\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.229, 0.224))  # Normalization for ImageNet pre-trained models\n",
    "    ])\n",
    "\n",
    "def load_models(device):\n",
    "    teacher_model = detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    teacher_model.to(device).eval()\n",
    "\n",
    "    student_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "    student_model.to(device).train()\n",
    "\n",
    "    return teacher_model, student_model\n",
    "\n",
    "def train_one_epoch(student_model, teacher_model, dataloader, optimizer, device, temperature=2):\n",
    "    student_model.train()\n",
    "    for images, _ in dataloader:\n",
    "        images = torch.stack([img.to(device) for img in images])  # Stack and move to device\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(images)\n",
    "            # Extract scores if output is a list of dictionaries\n",
    "            teacher_scores = torch.cat([o[\"scores\"] for o in teacher_outputs])\n",
    "\n",
    "        # Forward pass through the student model\n",
    "        student_outputs = student_model(images)\n",
    "        # YOLOv5 might output directly as a list of tensors depending on the version and configuration\n",
    "        if isinstance(student_outputs, torch.Tensor):\n",
    "            student_scores = student_outputs[..., 4]  # Assuming the 5th column in output are the confidences\n",
    "        elif isinstance(student_outputs, list):\n",
    "            student_scores = torch.cat([o[..., 4] for o in student_outputs])  # Adjust indexing if necessary\n",
    "\n",
    "        # Calculate the distillation loss using MSE on the scores\n",
    "        loss = distillation_loss(student_scores, teacher_scores, temperature)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def distillation_loss(student_scores, teacher_scores, temperature=2):\n",
    "    # Soften probabilities\n",
    "    soft_student_scores = torch.sigmoid(student_scores / temperature)\n",
    "    soft_teacher_scores = torch.sigmoid(teacher_scores / temperature)\n",
    "    # Calculate MSE loss\n",
    "    loss = torch.nn.functional.mse_loss(soft_student_scores, soft_teacher_scores)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    device = torch.device('mps')\n",
    "    dataset_root = '/Users/suvannanda/Desktop/objd/cocodata/train2017'\n",
    "    annotation_file = '/Users/suvannanda/Desktop/objd/cocodata/annotations/instances_train2017.json'\n",
    "    \n",
    "    coco_dataset = CustomCocoDataset(dataset_root, annotation_file, transform=get_transform())\n",
    "    data_loader = DataLoader(coco_dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=custom_collate)\n",
    "\n",
    "    teacher_model, student_model = load_models(device)\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model for one epoch\n",
    "    train_one_epoch(student_model, teacher_model, data_loader, optimizer, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f751530-97cc-40f8-a8d9-af4663e6dba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=37.50s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from collate_fn import custom_collate, CustomCocoDataset\n",
    "\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # Resize as needed\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.229, 0.224]),\n",
    "    ])\n",
    "\n",
    "def load_models(device):\n",
    "    # Teacher model: ResNet-101\n",
    "    teacher_model = models.resnet101(pretrained=True)\n",
    "    teacher_model.to(device).eval()\n",
    "\n",
    "    # Student model: ResNet-18\n",
    "    student_model = models.resnet18(pretrained=False)  # Start without pretrained weights\n",
    "    student_model.to(device).train()\n",
    "\n",
    "    return teacher_model, student_model\n",
    "\n",
    "def distillation_loss(student_logits, teacher_logits, temperature=2.0):\n",
    "    # Calculate softened logits\n",
    "    soft_student_logits = F.log_softmax(student_logits / temperature, dim=1)\n",
    "    soft_teacher_logits = F.softmax(teacher_logits / temperature, dim=1)\n",
    "\n",
    "    # Return the KL divergence loss\n",
    "    return F.kl_div(soft_student_logits, soft_teacher_logits, reduction='batchmean')\n",
    "\n",
    "def train_one_epoch(student_model, teacher_model, dataloader, optimizer, device, temperature=2.0):\n",
    "    student_model.train()\n",
    "    total_loss = 0\n",
    "    total_batches = 0\n",
    "\n",
    "    for images, annotations in dataloader:\n",
    "        # Filter out images without annotations\n",
    "        valid_data = [(img, ann) for img, ann in zip(images, annotations) if ann]\n",
    "        if not valid_data:\n",
    "            continue  # Skip this batch if no valid data\n",
    "\n",
    "        # Separate images and annotations lists\n",
    "        valid_images, valid_annotations = zip(*valid_data)\n",
    "        images = torch.stack(valid_images).to(device)\n",
    "\n",
    "        # Use the first available label from the annotations\n",
    "        labels = torch.tensor([ann[0]['label'] for ann in valid_annotations]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = teacher_model(images)\n",
    "\n",
    "        student_logits = student_model(images)\n",
    "        loss = distillation_loss(student_logits, teacher_logits, temperature)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_batches += 1\n",
    "\n",
    "    if total_batches > 0:\n",
    "        print(f\"Average training loss: {total_loss / total_batches}\")\n",
    "    else:\n",
    "        print(\"No valid batches were processed.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    device = torch.device('mps')\n",
    "    dataset_root = '/Users/suvannanda/Desktop/objd/cocodata/train2017'\n",
    "    annotation_file = '/Users/suvannanda/Desktop/objd/cocodata/annotations/instances_train2017.json'\n",
    "    \n",
    "    dataset = CustomCocoDataset(dataset_root, annotation_file, transform=get_transform())\n",
    "    data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4, collate_fn=custom_collate)\n",
    "\n",
    "    teacher_model, student_model = load_models(device)\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model for one epoch (or more as needed)\n",
    "    train_one_epoch(student_model, teacher_model, data_loader, optimizer, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bb6f1f-0cd8-4ae4-9cf4-f8a771745ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
